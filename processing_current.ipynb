{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction and Hypothesis \n",
    "\n",
    "Using long historical texts (i.e., novels) to learn data science for the humanities provided many insights throughout the semester. However, our group was quite interested by the social media data that we discussed towards the end of the semester because a lot of meaning can be derived from short texts (e.g., Tweets, posts, etc.). We were also interested by the dynamic nature of this data. In order to balance the ethical and processing concerns of social media data, we decided to look at Yelp restaurant reviews as a way to analyze \"medium length\" text data. We were also interested in Yelp reviews because they correspond directly to a number rating (1-5 stars) that the user writing the review determines. Because everyone has a subjective understanding of a star rating, we thought this could pose some interesting challenges when analyzing this data.\n",
    "\n",
    "**Research Question & Hypothesis**\n",
    "\n",
    "How accurately can various algorithms correctly classify star rating based on review text?\n",
    "What NLP method is most effective for identifying star numbers based on review text?\n",
    "- Tf-idf Lemma feature matrices?\n",
    "- Average review sentiment feature matrix?\n",
    "\n",
    "How accurately can topic modeling paired with various algorithms identify what type of restaurant a review is written about?\n",
    "- Restaurant vs other type of business?\n",
    "- Specific types of restaurants in a multiclass classification?\n",
    "- Specific types of restaurants in single item classification (Mexican or not)?\n",
    "\n",
    "Our hypothesis for the first two questions was that given the opinionated nature of reviews, both lemma feature matrices as well as sentiment score feature matrices would be able to classify reviews into star levels much better than baseline accuracy. We were less convinced that topic modelling would successfully reveal restaurant cuisines, because often reviews just say things like \"Great service, and the food was really tasty! We will be back soon.\" which does not include any information on the type of food served at the restaurant. We hypothesized that a binary cuisine classifier would perform much better than a multiclass cuisine question because the small number of cuisine-specific topics would be weighted heavily for the cuisine-specific reviews.\n",
    "\n",
    "***NOTE: Our results are presented throughout the body section, so our \"Results\" section is a shorter summary of our findings.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Data and Methods \n",
    "\n",
    "Our data is sourced directly from [Yelp](yelp.com). The original dataset has 7 million customer reviews for restaurants and stores. Each row in the reviews dataset has:\n",
    "- review text\n",
    "- 1-5 star rating\n",
    "- 'useful 'cool' and 'funny' votes on the review\n",
    "- user, business, and review ids for joining among the user, business, and review tables they publish. We joined the review table with the businesses table for our attempt at classifying restaurants later in this notebook.\n",
    "\n",
    "The businesses dataset has:\n",
    "- Business name\n",
    "- Business ID\n",
    "- Business location information\n",
    "- Business hours\n",
    "- Business category list\n",
    "- Average Star Rating\n",
    "- Total Reviews\n",
    "\n",
    "Originally, we sourced 7 million reviews from Yelp which they make available in json format. Then we ran a .py script (submitted along with this project which we found in a github repository built to help process this Yelp data, and then slightly modified for our needs) to convert the json into a csv, because loading in a random subset of the json was taking excessively long in jupyter lab. Next, in a previous notebook (submitted along with this project) we randomly selected 14,997 (approx 15,000) reviews, and saved them into a separate file, called selected_yelp_reviews.csv.\n",
    "\n",
    "Our entire project relies on classification using different feature matrix methods. We use lemmatized tokens, sentiment scores, and topic models to answer different classification questions based on different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import spacy\n",
    "import string\n",
    "import math\n",
    "import pathlib\n",
    "import unicodedata\n",
    "import copy\n",
    "import re\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from   glob import glob\n",
    "from   nltk import word_tokenize, sent_tokenize\n",
    "from   nltk.corpus import stopwords\n",
    "from   collections import Counter, defaultdict\n",
    "from   matplotlib import pyplot as plt\n",
    "\n",
    "from   sklearn.feature_extraction import DictVectorizer\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_extraction.text import CountVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from   sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from   sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from   sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay, precision_score, accuracy_score\n",
    "from   sklearn.cluster import KMeans, SpectralClustering, DBSCAN, OPTICS, AgglomerativeClustering\n",
    "from   sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from   sklearn.decomposition import TruncatedSVD\n",
    "from   sklearn.tree import DecisionTreeClassifier\n",
    "from   sklearn.ensemble import RandomForestClassifier\n",
    "from   sklearn.naive_bayes import MultinomialNB\n",
    "from   sklearn.decomposition import LatentDirichletAllocation\n",
    "from   sklearn.neighbors import KNeighborsClassifier\n",
    "from   sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M3xME4pvnOYi06q2upH3vw</td>\n",
       "      <td>0</td>\n",
       "      <td>pEwlvpFtLSoYok1i9F0Tew</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a nice place. Really nice! Great service ...</td>\n",
       "      <td>2012-07-16 01:31:26</td>\n",
       "      <td>0</td>\n",
       "      <td>M0c99tzIJPIbrY_RAO7KSQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VbGus5yJEza4G0blt2sPqA</td>\n",
       "      <td>0</td>\n",
       "      <td>oSWY_2X9CApWlJrN0TsA6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My go to place in IN when visiting family!  Da...</td>\n",
       "      <td>2016-06-11 20:19:32</td>\n",
       "      <td>0</td>\n",
       "      <td>Q8q-1MZTYPL9ZBmAeoMKVg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0zPBuXxQuxHOQmA4ehcvQ</td>\n",
       "      <td>0</td>\n",
       "      <td>iOQ_bnKI5HfPbH43DMAw6w</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This place is good. For the lofty prices the p...</td>\n",
       "      <td>2013-01-27 19:22:26</td>\n",
       "      <td>0</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J2nuqbMp9ooEa_0QD9kjvg</td>\n",
       "      <td>0</td>\n",
       "      <td>qO--SRLwiNfGGKAPeSGHpA</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>For a $16 haircut, I was expecting an OK-looki...</td>\n",
       "      <td>2011-08-26 01:37:56</td>\n",
       "      <td>0</td>\n",
       "      <td>eaV07HGOcyb27XobHVl8LQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X23bt-XPgRC5yqtrSgp9Jg</td>\n",
       "      <td>3</td>\n",
       "      <td>i7CqIbvjgr6M8qGuyOV98g</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I wish I had read the other reviews before set...</td>\n",
       "      <td>2012-03-01 20:14:15</td>\n",
       "      <td>0</td>\n",
       "      <td>-pgTW7620zWdXMOczX0www</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  useful               review_id  cool  stars  \\\n",
       "0  M3xME4pvnOYi06q2upH3vw       0  pEwlvpFtLSoYok1i9F0Tew     0    4.0   \n",
       "1  VbGus5yJEza4G0blt2sPqA       0  oSWY_2X9CApWlJrN0TsA6Q     0    5.0   \n",
       "2  n0zPBuXxQuxHOQmA4ehcvQ       0  iOQ_bnKI5HfPbH43DMAw6w     0    3.0   \n",
       "3  J2nuqbMp9ooEa_0QD9kjvg       0  qO--SRLwiNfGGKAPeSGHpA     0    5.0   \n",
       "4  X23bt-XPgRC5yqtrSgp9Jg       3  i7CqIbvjgr6M8qGuyOV98g     1    1.0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  It's a nice place. Really nice! Great service ...  2012-07-16 01:31:26   \n",
       "1  My go to place in IN when visiting family!  Da...  2016-06-11 20:19:32   \n",
       "2  This place is good. For the lofty prices the p...  2013-01-27 19:22:26   \n",
       "3  For a $16 haircut, I was expecting an OK-looki...  2011-08-26 01:37:56   \n",
       "4  I wish I had read the other reviews before set...  2012-03-01 20:14:15   \n",
       "\n",
       "   funny             business_id  \n",
       "0      0  M0c99tzIJPIbrY_RAO7KSQ  \n",
       "1      0  Q8q-1MZTYPL9ZBmAeoMKVg  \n",
       "2      0  YtSqYv1Q_pOltsVPSx54SA  \n",
       "3      0  eaV07HGOcyb27XobHVl8LQ  \n",
       "4      0  -pgTW7620zWdXMOczX0www  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('selected_yelp_reviews.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph initial rating distribution\n",
    "plt.hist(reviews['stars'], bins=[1,2,3,4,5,6], align='left', rwidth=0.75)\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('# of Reviews')\n",
    "plt.title(\"Distribution of Review Ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see here, the target variable (star rating) has very imbalanced classes, ranging from 1,000 2-star reviews to 7,000 5-star reviews. This may result in a bias toward 5-star reviews and against 2-star reviews in our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load business dataset\n",
    "businesses = pd.read_json(\"yelp_academic_dataset_business.json\", lines=True)\n",
    "\n",
    "#combine with reviews metadata\n",
    "combined = reviews.merge(businesses, on='business_id', how='left')\n",
    "\n",
    "# drop row with no categories\n",
    "combined = combined.drop(9777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M3xME4pvnOYi06q2upH3vw</td>\n",
       "      <td>0</td>\n",
       "      <td>pEwlvpFtLSoYok1i9F0Tew</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a nice place. Really nice! Great service ...</td>\n",
       "      <td>2012-07-16 01:31:26</td>\n",
       "      <td>0</td>\n",
       "      <td>M0c99tzIJPIbrY_RAO7KSQ</td>\n",
       "      <td>Hyatt Regency St. Louis at the Arch</td>\n",
       "      <td>...</td>\n",
       "      <td>MO</td>\n",
       "      <td>63102</td>\n",
       "      <td>38.626221</td>\n",
       "      <td>-90.187770</td>\n",
       "      <td>3.5</td>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': 'u'free'', 'BusinessAcceptsCreditCard...</td>\n",
       "      <td>Event Planning &amp; Services, Venues &amp; Event Spac...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VbGus5yJEza4G0blt2sPqA</td>\n",
       "      <td>0</td>\n",
       "      <td>oSWY_2X9CApWlJrN0TsA6Q</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My go to place in IN when visiting family!  Da...</td>\n",
       "      <td>2016-06-11 20:19:32</td>\n",
       "      <td>0</td>\n",
       "      <td>Q8q-1MZTYPL9ZBmAeoMKVg</td>\n",
       "      <td>Lilly Nails &amp; Spa</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>46038</td>\n",
       "      <td>39.956701</td>\n",
       "      <td>-86.023032</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Restau...</td>\n",
       "      <td>Beauty &amp; Spas, Nail Salons, Day Spas</td>\n",
       "      <td>{'Monday': '10:0-19:30', 'Tuesday': '10:0-19:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n0zPBuXxQuxHOQmA4ehcvQ</td>\n",
       "      <td>0</td>\n",
       "      <td>iOQ_bnKI5HfPbH43DMAw6w</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This place is good. For the lofty prices the p...</td>\n",
       "      <td>2013-01-27 19:22:26</td>\n",
       "      <td>0</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsAttire': 'u'dressy'', 'Restaurant...</td>\n",
       "      <td>Wine Bars, Restaurants, Nightlife, Steakhouses...</td>\n",
       "      <td>{'Wednesday': '16:30-22:0', 'Thursday': '16:30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J2nuqbMp9ooEa_0QD9kjvg</td>\n",
       "      <td>0</td>\n",
       "      <td>qO--SRLwiNfGGKAPeSGHpA</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>For a $16 haircut, I was expecting an OK-looki...</td>\n",
       "      <td>2011-08-26 01:37:56</td>\n",
       "      <td>0</td>\n",
       "      <td>eaV07HGOcyb27XobHVl8LQ</td>\n",
       "      <td>Jean Madeline Aveda Institute Salon</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>19104</td>\n",
       "      <td>39.955982</td>\n",
       "      <td>-75.201914</td>\n",
       "      <td>3.5</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForKids': 'True', 'ByAppointmentOnly': '...</td>\n",
       "      <td>Specialty Schools, Nail Salons, Hair Salons, C...</td>\n",
       "      <td>{'Tuesday': '16:45-21:0', 'Wednesday': '16:45-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X23bt-XPgRC5yqtrSgp9Jg</td>\n",
       "      <td>3</td>\n",
       "      <td>i7CqIbvjgr6M8qGuyOV98g</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I wish I had read the other reviews before set...</td>\n",
       "      <td>2012-03-01 20:14:15</td>\n",
       "      <td>0</td>\n",
       "      <td>-pgTW7620zWdXMOczX0www</td>\n",
       "      <td>Arizona Stagecoach</td>\n",
       "      <td>...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85756</td>\n",
       "      <td>32.087229</td>\n",
       "      <td>-110.923462</td>\n",
       "      <td>2.5</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Tours, Travel Services, Airport Shuttles, Tran...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  useful               review_id  cool  stars_x  \\\n",
       "0  M3xME4pvnOYi06q2upH3vw       0  pEwlvpFtLSoYok1i9F0Tew     0      4.0   \n",
       "1  VbGus5yJEza4G0blt2sPqA       0  oSWY_2X9CApWlJrN0TsA6Q     0      5.0   \n",
       "2  n0zPBuXxQuxHOQmA4ehcvQ       0  iOQ_bnKI5HfPbH43DMAw6w     0      3.0   \n",
       "3  J2nuqbMp9ooEa_0QD9kjvg       0  qO--SRLwiNfGGKAPeSGHpA     0      5.0   \n",
       "4  X23bt-XPgRC5yqtrSgp9Jg       3  i7CqIbvjgr6M8qGuyOV98g     1      1.0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  It's a nice place. Really nice! Great service ...  2012-07-16 01:31:26   \n",
       "1  My go to place in IN when visiting family!  Da...  2016-06-11 20:19:32   \n",
       "2  This place is good. For the lofty prices the p...  2013-01-27 19:22:26   \n",
       "3  For a $16 haircut, I was expecting an OK-looki...  2011-08-26 01:37:56   \n",
       "4  I wish I had read the other reviews before set...  2012-03-01 20:14:15   \n",
       "\n",
       "   funny             business_id                                 name  ...  \\\n",
       "0      0  M0c99tzIJPIbrY_RAO7KSQ  Hyatt Regency St. Louis at the Arch  ...   \n",
       "1      0  Q8q-1MZTYPL9ZBmAeoMKVg                    Lilly Nails & Spa  ...   \n",
       "2      0  YtSqYv1Q_pOltsVPSx54SA                    Rittenhouse Grill  ...   \n",
       "3      0  eaV07HGOcyb27XobHVl8LQ  Jean Madeline Aveda Institute Salon  ...   \n",
       "4      0  -pgTW7620zWdXMOczX0www                   Arizona Stagecoach  ...   \n",
       "\n",
       "  state postal_code   latitude   longitude  stars_y  review_count  is_open  \\\n",
       "0    MO       63102  38.626221  -90.187770      3.5           430        1   \n",
       "1    IN       46038  39.956701  -86.023032      4.0            68        1   \n",
       "2    PA       19103  39.948949  -75.169532      3.5           290        1   \n",
       "3    PA       19104  39.955982  -75.201914      3.5           190        1   \n",
       "4    AZ       85756  32.087229 -110.923462      2.5            41        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'WiFi': 'u'free'', 'BusinessAcceptsCreditCard...   \n",
       "1  {'BusinessAcceptsCreditCards': 'True', 'Restau...   \n",
       "2  {'RestaurantsAttire': 'u'dressy'', 'Restaurant...   \n",
       "3  {'GoodForKids': 'True', 'ByAppointmentOnly': '...   \n",
       "4                                               None   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Event Planning & Services, Venues & Event Spac...   \n",
       "1               Beauty & Spas, Nail Salons, Day Spas   \n",
       "2  Wine Bars, Restaurants, Nightlife, Steakhouses...   \n",
       "3  Specialty Schools, Nail Salons, Hair Salons, C...   \n",
       "4  Tours, Travel Services, Airport Shuttles, Tran...   \n",
       "\n",
       "                                               hours  \n",
       "0  {'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...  \n",
       "1  {'Monday': '10:0-19:30', 'Tuesday': '10:0-19:3...  \n",
       "2  {'Wednesday': '16:30-22:0', 'Thursday': '16:30...  \n",
       "3  {'Tuesday': '16:45-21:0', 'Wednesday': '16:45-...  \n",
       "4  {'Monday': '0:0-0:0', 'Tuesday': '0:0-0:0', 'W...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatized TFIDF Section\n",
    "\n",
    "Here, we used lemmatized reviews and created a tf-idf feature matrix to try and classify review star-ratings based on review text. We used a min_df of 0.05 so that we would be focusing on lemmas used in enough reviews that their presence would be informative. We then scaled the feature matrix, and compared scores from five classifiers, including a dummy classifier to serve as baseline accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teo's lemmatizer function from ps07\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatizer(s, nlp=nlp):\n",
    "    \n",
    "    lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "    doc = nlp(s)\n",
    "    \n",
    "    return [token.lemma_ for token in doc if token.pos_ != \"PUNCT\" and token.pos_ != \"SPACE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "## We saved the output of this vectorizer to save time in future runs of the notebook.\n",
    "\n",
    "##%%time\n",
    "##\n",
    "### making tf-idf vectorizer with lemmas\n",
    "##lemma_vectorizer = TfidfVectorizer(\n",
    "##    input = 'content',\n",
    "##    encoding = 'utf-8',\n",
    "##    strip_accents = 'unicode',\n",
    "##    lowercase = True,\n",
    "##    tokenizer = lemmatizer,\n",
    "##    min_df = 0.05,\n",
    "##    use_idf=True\n",
    "##)\n",
    "##\n",
    "##raw_lemma = lemma_vectorizer.fit_transform(reviews['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##with open('X_raw_lemma.pickle', 'wb') as f:\n",
    "##    pickle.dump(raw_lemma, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lemma = pd.read_pickle(r'X_raw_lemma.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix:  (14997, 237)\n"
     ]
    }
   ],
   "source": [
    "# scaling the vector\n",
    "scaler = StandardScaler()\n",
    "scaled_feat_matrix_lemma = scaler.fit_transform(raw_lemma.toarray())\n",
    "print('Shape of feature matrix: ', scaled_feat_matrix_lemma.shape)\n",
    "#making gold labels\n",
    "y_stars = reviews['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from mp02 problem set\n",
    "def compare_scores(scores_dict):\n",
    "    '''\n",
    "    Takes a dictionary of cross_validate scores.\n",
    "    Returns a color-coded Pandas dataframe that summarizes those scores.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(scores_dict).T.applymap(np.mean).style.background_gradient(cmap='RdYlGn')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_163a4_row0_col0, #T_163a4_row0_col1, #T_163a4_row0_col2, #T_163a4_row0_col3, #T_163a4_row0_col4, #T_163a4_row0_col5, #T_163a4_row0_col6, #T_163a4_row0_col7, #T_163a4_row1_col0, #T_163a4_row2_col1, #T_163a4_row3_col1 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row1_col1, #T_163a4_row2_col2, #T_163a4_row2_col3, #T_163a4_row2_col4, #T_163a4_row2_col5, #T_163a4_row2_col6, #T_163a4_row2_col7, #T_163a4_row4_col0 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row1_col2, #T_163a4_row1_col4, #T_163a4_row1_col7 {\n",
       "  background-color: #dcf08f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row1_col3 {\n",
       "  background-color: #f5fbb2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row1_col5 {\n",
       "  background-color: #eef8a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row1_col6, #T_163a4_row4_col6 {\n",
       "  background-color: #fffcba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row2_col0 {\n",
       "  background-color: #c62027;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row3_col0 {\n",
       "  background-color: #ef633f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row3_col2, #T_163a4_row3_col4, #T_163a4_row3_col7 {\n",
       "  background-color: #fff1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row3_col3 {\n",
       "  background-color: #fbfdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row3_col5 {\n",
       "  background-color: #fffdbc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row3_col6 {\n",
       "  background-color: #fffbb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row4_col1 {\n",
       "  background-color: #d22b27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row4_col2, #T_163a4_row4_col4, #T_163a4_row4_col7 {\n",
       "  background-color: #30a356;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_163a4_row4_col3 {\n",
       "  background-color: #a2d76a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_163a4_row4_col5 {\n",
       "  background-color: #c1e57b;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_163a4_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision_weighted</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall_weighted</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1_weighted</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_163a4_level0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "      <td id=\"T_163a4_row0_col0\" class=\"data row0 col0\" >0.012198</td>\n",
       "      <td id=\"T_163a4_row0_col1\" class=\"data row0 col1\" >0.015189</td>\n",
       "      <td id=\"T_163a4_row0_col2\" class=\"data row0 col2\" >0.297061</td>\n",
       "      <td id=\"T_163a4_row0_col3\" class=\"data row0 col3\" >0.299731</td>\n",
       "      <td id=\"T_163a4_row0_col4\" class=\"data row0 col4\" >0.297061</td>\n",
       "      <td id=\"T_163a4_row0_col5\" class=\"data row0 col5\" >0.298219</td>\n",
       "      <td id=\"T_163a4_row0_col6\" class=\"data row0 col6\" >0.198668</td>\n",
       "      <td id=\"T_163a4_row0_col7\" class=\"data row0 col7\" >0.297061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_163a4_level0_row1\" class=\"row_heading level0 row1\" >kNN</th>\n",
       "      <td id=\"T_163a4_row1_col0\" class=\"data row1 col0\" >0.024109</td>\n",
       "      <td id=\"T_163a4_row1_col1\" class=\"data row1 col1\" >0.945586</td>\n",
       "      <td id=\"T_163a4_row1_col2\" class=\"data row1 col2\" >0.486764</td>\n",
       "      <td id=\"T_163a4_row1_col3\" class=\"data row1 col3\" >0.448355</td>\n",
       "      <td id=\"T_163a4_row1_col4\" class=\"data row1 col4\" >0.486764</td>\n",
       "      <td id=\"T_163a4_row1_col5\" class=\"data row1 col5\" >0.458715</td>\n",
       "      <td id=\"T_163a4_row1_col6\" class=\"data row1 col6\" >0.332614</td>\n",
       "      <td id=\"T_163a4_row1_col7\" class=\"data row1 col7\" >0.486764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_163a4_level0_row2\" class=\"row_heading level0 row2\" >Logit</th>\n",
       "      <td id=\"T_163a4_row2_col0\" class=\"data row2 col0\" >0.940878</td>\n",
       "      <td id=\"T_163a4_row2_col1\" class=\"data row2 col1\" >0.017234</td>\n",
       "      <td id=\"T_163a4_row2_col2\" class=\"data row2 col2\" >0.617055</td>\n",
       "      <td id=\"T_163a4_row2_col3\" class=\"data row2 col3\" >0.581679</td>\n",
       "      <td id=\"T_163a4_row2_col4\" class=\"data row2 col4\" >0.617055</td>\n",
       "      <td id=\"T_163a4_row2_col5\" class=\"data row2 col5\" >0.592195</td>\n",
       "      <td id=\"T_163a4_row2_col6\" class=\"data row2 col6\" >0.472005</td>\n",
       "      <td id=\"T_163a4_row2_col7\" class=\"data row2 col7\" >0.617055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_163a4_level0_row3\" class=\"row_heading level0 row3\" >decisionTree</th>\n",
       "      <td id=\"T_163a4_row3_col0\" class=\"data row3 col0\" >2.561464</td>\n",
       "      <td id=\"T_163a4_row3_col1\" class=\"data row3 col1\" >0.017710</td>\n",
       "      <td id=\"T_163a4_row3_col2\" class=\"data row3 col2\" >0.443087</td>\n",
       "      <td id=\"T_163a4_row3_col3\" class=\"data row3 col3\" >0.443397</td>\n",
       "      <td id=\"T_163a4_row3_col4\" class=\"data row3 col4\" >0.443087</td>\n",
       "      <td id=\"T_163a4_row3_col5\" class=\"data row3 col5\" >0.442947</td>\n",
       "      <td id=\"T_163a4_row3_col6\" class=\"data row3 col6\" >0.331157</td>\n",
       "      <td id=\"T_163a4_row3_col7\" class=\"data row3 col7\" >0.443087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_163a4_level0_row4\" class=\"row_heading level0 row4\" >randomForest</th>\n",
       "      <td id=\"T_163a4_row4_col0\" class=\"data row4 col0\" >13.897068</td>\n",
       "      <td id=\"T_163a4_row4_col1\" class=\"data row4 col1\" >0.099873</td>\n",
       "      <td id=\"T_163a4_row4_col2\" class=\"data row4 col2\" >0.574648</td>\n",
       "      <td id=\"T_163a4_row4_col3\" class=\"data row4 col3\" >0.498620</td>\n",
       "      <td id=\"T_163a4_row4_col4\" class=\"data row4 col4\" >0.574648</td>\n",
       "      <td id=\"T_163a4_row4_col5\" class=\"data row4 col5\" >0.488434</td>\n",
       "      <td id=\"T_163a4_row4_col6\" class=\"data row4 col6\" >0.332322</td>\n",
       "      <td id=\"T_163a4_row4_col7\" class=\"data row4 col7\" >0.574648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2e5f7ce71f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        scaled_feat_matrix_lemma, # feature matrix\n",
    "        y_stars, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### These results are not bad at all. The best classifier, Logit, performed about 32% better than baseline accuracy, more than doubling baseline accuracy. This is in line with our original hypothesis that tfidf lemmas would be very informative relative to baseline accuracy. That being said, 62% is still not particularly high accuracy, and so below we take steps to try and improve it.\n",
    "\n",
    "Next, we decided to filter down our feature matrix to the 50 most informative features, to try and reduce potential overfitting and improve accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##Now selecting top 50 of 237 features to see how it affects the cv accuracy\n",
    "\n",
    "selector = SelectKBest(score_func = mutual_info_regression, k = 50)\n",
    "X_top_50 = selector.fit_transform(scaled_feat_matrix_lemma, y_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_365820/3892084081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# Store cross-validation results in a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     scores[classifier] = cross_validate( # perform cross-validation\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# classifier object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mX_top_50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# feature matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\3350\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        X_top_50, # feature matrix\n",
    "        y_stars, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring =['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall a feature matrix of the top 50 features results in worse classifier performance (mean cross validated accuracy scores of 0.58 vs. 0.62 for Logit for example, the best performing algorithm regardless of feature matrix), so we continued the analysis with the full feature matrix.\n",
    "\n",
    "From here, we wanted to explore new scoring schemes. We recognize that misclassifying a 1-star review as 4-star is worse than misclassifying a 1-star review as 2-star. As such, the following code explores a new scoring scheme where classifications are correct provided they predict stars correctly or are 1 star off. To do this, we needed to train test and split the data and fit a new logistic regression algorithm to access specific predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:  0.6246464646464647 = 62.5%\n"
     ]
    }
   ],
   "source": [
    "# train test split of the full feature matrix\n",
    "LogReg= LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_feat_matrix_lemma, y_stars, test_size=0.33, random_state=42)\n",
    "LogReg.fit(X_train, y_train)\n",
    "preds = LogReg.predict(X_test)\n",
    "print('Correct Predictions: ', accuracy_score(y_test, preds), '= 62.5%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions that were correct or 1 star off:  4341 / 4950 or  87.7 %\n"
     ]
    }
   ],
   "source": [
    "count_within1 = 0\n",
    "for x,y in zip(preds, y_test):\n",
    "    if(abs(x-y) <= 1): count_within1 +=1\n",
    "    \n",
    "total = len(preds)\n",
    "\n",
    "print('Predictions that were correct or 1 star off: ', count_within1, '/', total, 'or ', round((count_within1/total) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the two accuracies (62.5% vs 87.7%) we can get an idea of how closely the classifier groups many of the star ratings within one star. While this method is not the most refined, we just wanted to see how much we could improve the accuracy by relaxing what a correct classification was for this specific train test split. This is encouraging because it means that the the Logit, even when wrong, is still close to the correct class. We will not be using this method for future analysis, but it did provide useful insight. For even more detailed insight, we now take a look at a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, preds, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Review Classification Success')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above shows how successful our logistic regression classification was for each of the five star ratings (1-5). The ideal graph would be all 1 and green on the middle diagonal, meaning that all 1 star ratings were classified as 1, all 2 star ratings were classified as 2, and so on. However, as the confusion matrix shows, the classification was not very successful for the rating numbers 2, 3, and 4. The classifier was fairly good for predicting 1 star ratings (75% accuracy) and 5 star ratings (84% accuracy) which makes sense, because these are most likely skewed by strong language. If strong negative or positive language is used, it is likely that reviewers also associate that strong review with a decisive score (1 or 5). The middle numbers are more difficult to predict because of the subjectivity that each reviewer has when matching a star rating to a text review. The language that one user decides is a 2 star rating may be very different from the language of a different 2 star review, which affects the classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next blocks of code, we play around with a different \"relaxed scoring\" to try to improve accuracy. By grouping the ratings into three categories, we refine our method of counting classifications that are one star rating away in either direction. In this case, we group ratings of 1 and 2 as \"bad\", 3 as \"okay\", and 4 and 5 as \"good\". As shown below, the accuracy improves relative to strict scoring, but is still not quite as good as the 1 star off method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_3cls = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in y_test]\n",
    "preds_3cls  = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy According to Relaxed Scoring Scheme:  0.8072727272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy According to Relaxed Scoring Scheme: \", sum(np.array([1 if x==y else 0 for x,y in zip(y_test_3cls, preds_3cls)])) / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test_3cls, preds_3cls, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Classification Success According to Relaxed Scoring Scheme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above shows how successful our logistic regression classification was after creating three groups of ratings.\n",
    "- The \"good\" group has the highest accuracy, meaning the classifier was able to identify 4 and 5 star ratings based on the text review very well (91% of the time). This makes sense because positive sentiments more easily and readily align with 4 and 5 star ratings. \n",
    "- The accuracy of the \"bad\" group is not as good, the classifier performed better when just classifying 1 star ratings (see earlier confusion matrix). This is surprising because grouping 4 and 5 star ratings helped, but grouping 1 and 2 star ratings. This seems to be because 4 star ratings are more often confused with 5 star ratings than 2 star ratings are confused with 1 star ratings. This could have to do with the bias in the original dataset, where there are tons of 5 star ratings relative to 2 star ratings (7k vs 1k).\n",
    "- The \"okay\" category performs poorly, which makes sense for two reasons. First, because it only includes one star rating (3), there is a smaller successful \"target area\" that the classifier will succeed in. Second, and to us more insightful, is again the idea that medium reviews are more likely to span different number ratings.\n",
    "\n",
    "To explore further, we could group 2 and 3 together as \"okay\" and have 1 star be the \"bad\" category.\n",
    "\n",
    "\n",
    "As a final attempt to raise accuracy, below I re-vectorized with max_df initialized to 0.5, to see whether limiting to lemmas present in a maximum of 50% of reviews would provide a better tuned feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Vectorizer attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 40s\n"
     ]
    }
   ],
   "source": [
    "## saved this file to avoid rerunning every time\n",
    "\n",
    "##%%time\n",
    "\n",
    "### making tf-idf vectorizer with lemmas\n",
    "##lemma_vectorizer_2 = TfidfVectorizer(\n",
    "##    input = 'content',\n",
    "##    encoding = 'utf-8',\n",
    "##    strip_accents = 'unicode',\n",
    "##    lowercase = True,\n",
    "##    tokenizer = lemmatizer,\n",
    "##    min_df = 0.05,\n",
    "##    max_df = 0.5,\n",
    "##    use_idf=True\n",
    "##)\n",
    "##\n",
    "##raw_lemma_2 = lemma_vectorizer_2.fit_transform(reviews['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('X_raw_lemma_2.pickle', 'wb') as f:\n",
    "#    pickle.dump(raw_lemma_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_lemma_2 = pd.read_pickle(r'X_raw_lemma_2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix:  (14997, 225)\n"
     ]
    }
   ],
   "source": [
    "# scaling the vector\n",
    "scaler = StandardScaler()\n",
    "scaled_feat_matrix_lemma_2 = scaler.fit_transform(raw_lemma_2.toarray())\n",
    "print('Shape of feature matrix: ', scaled_feat_matrix_lemma_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very smiliar to the size of the last full feature matrix, it simply has 12 fewer columns. This makes me think that perhaps this method may not have actually changed much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ab35_row0_col0, #T_3ab35_row0_col1, #T_3ab35_row0_col2, #T_3ab35_row0_col3, #T_3ab35_row0_col4, #T_3ab35_row0_col5, #T_3ab35_row0_col6, #T_3ab35_row0_col7, #T_3ab35_row1_col0, #T_3ab35_row2_col1, #T_3ab35_row3_col1 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row1_col1, #T_3ab35_row2_col2, #T_3ab35_row2_col3, #T_3ab35_row2_col4, #T_3ab35_row2_col5, #T_3ab35_row2_col6, #T_3ab35_row2_col7, #T_3ab35_row4_col0 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row1_col2, #T_3ab35_row1_col4, #T_3ab35_row1_col7 {\n",
       "  background-color: #c1e57b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row1_col3 {\n",
       "  background-color: #fff1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row1_col5 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row1_col6 {\n",
       "  background-color: #f98e52;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row2_col0 {\n",
       "  background-color: #ca2427;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row3_col0 {\n",
       "  background-color: #f67c4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row3_col2, #T_3ab35_row3_col4, #T_3ab35_row3_col7 {\n",
       "  background-color: #feffbe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row3_col3 {\n",
       "  background-color: #e6f59d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row3_col5 {\n",
       "  background-color: #ecf7a6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row3_col6 {\n",
       "  background-color: #e8f59f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row4_col1 {\n",
       "  background-color: #ce2827;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row4_col2, #T_3ab35_row4_col4, #T_3ab35_row4_col7 {\n",
       "  background-color: #1e9a51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ab35_row4_col3 {\n",
       "  background-color: #93d168;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row4_col5 {\n",
       "  background-color: #afdd70;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ab35_row4_col6 {\n",
       "  background-color: #fafdb8;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ab35_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >fit_time</th>\n",
       "      <th class=\"col_heading level0 col1\" >score_time</th>\n",
       "      <th class=\"col_heading level0 col2\" >test_accuracy</th>\n",
       "      <th class=\"col_heading level0 col3\" >test_precision_weighted</th>\n",
       "      <th class=\"col_heading level0 col4\" >test_recall_weighted</th>\n",
       "      <th class=\"col_heading level0 col5\" >test_f1_weighted</th>\n",
       "      <th class=\"col_heading level0 col6\" >test_f1_macro</th>\n",
       "      <th class=\"col_heading level0 col7\" >test_f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ab35_level0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "      <td id=\"T_3ab35_row0_col0\" class=\"data row0 col0\" >0.015039</td>\n",
       "      <td id=\"T_3ab35_row0_col1\" class=\"data row0 col1\" >0.018689</td>\n",
       "      <td id=\"T_3ab35_row0_col2\" class=\"data row0 col2\" >0.304261</td>\n",
       "      <td id=\"T_3ab35_row0_col3\" class=\"data row0 col3\" >0.302782</td>\n",
       "      <td id=\"T_3ab35_row0_col4\" class=\"data row0 col4\" >0.304261</td>\n",
       "      <td id=\"T_3ab35_row0_col5\" class=\"data row0 col5\" >0.303410</td>\n",
       "      <td id=\"T_3ab35_row0_col6\" class=\"data row0 col6\" >0.202333</td>\n",
       "      <td id=\"T_3ab35_row0_col7\" class=\"data row0 col7\" >0.304261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ab35_level0_row1\" class=\"row_heading level0 row1\" >kNN</th>\n",
       "      <td id=\"T_3ab35_row1_col0\" class=\"data row1 col0\" >0.020565</td>\n",
       "      <td id=\"T_3ab35_row1_col1\" class=\"data row1 col1\" >1.066254</td>\n",
       "      <td id=\"T_3ab35_row1_col2\" class=\"data row1 col2\" >0.501700</td>\n",
       "      <td id=\"T_3ab35_row1_col3\" class=\"data row1 col3\" >0.425770</td>\n",
       "      <td id=\"T_3ab35_row1_col4\" class=\"data row1 col4\" >0.501700</td>\n",
       "      <td id=\"T_3ab35_row1_col5\" class=\"data row1 col5\" >0.414526</td>\n",
       "      <td id=\"T_3ab35_row1_col6\" class=\"data row1 col6\" >0.267269</td>\n",
       "      <td id=\"T_3ab35_row1_col7\" class=\"data row1 col7\" >0.501700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ab35_level0_row2\" class=\"row_heading level0 row2\" >Logit</th>\n",
       "      <td id=\"T_3ab35_row2_col0\" class=\"data row2 col0\" >1.015093</td>\n",
       "      <td id=\"T_3ab35_row2_col1\" class=\"data row2 col1\" >0.021529</td>\n",
       "      <td id=\"T_3ab35_row2_col2\" class=\"data row2 col2\" >0.609987</td>\n",
       "      <td id=\"T_3ab35_row2_col3\" class=\"data row2 col3\" >0.572022</td>\n",
       "      <td id=\"T_3ab35_row2_col4\" class=\"data row2 col4\" >0.609987</td>\n",
       "      <td id=\"T_3ab35_row2_col5\" class=\"data row2 col5\" >0.582478</td>\n",
       "      <td id=\"T_3ab35_row2_col6\" class=\"data row2 col6\" >0.460732</td>\n",
       "      <td id=\"T_3ab35_row2_col7\" class=\"data row2 col7\" >0.609987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ab35_level0_row3\" class=\"row_heading level0 row3\" >decisionTree</th>\n",
       "      <td id=\"T_3ab35_row3_col0\" class=\"data row3 col0\" >2.924698</td>\n",
       "      <td id=\"T_3ab35_row3_col1\" class=\"data row3 col1\" >0.021045</td>\n",
       "      <td id=\"T_3ab35_row3_col2\" class=\"data row3 col2\" >0.458092</td>\n",
       "      <td id=\"T_3ab35_row3_col3\" class=\"data row3 col3\" >0.454936</td>\n",
       "      <td id=\"T_3ab35_row3_col4\" class=\"data row3 col4\" >0.458092</td>\n",
       "      <td id=\"T_3ab35_row3_col5\" class=\"data row3 col5\" >0.456261</td>\n",
       "      <td id=\"T_3ab35_row3_col6\" class=\"data row3 col6\" >0.347424</td>\n",
       "      <td id=\"T_3ab35_row3_col7\" class=\"data row3 col7\" >0.458092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ab35_level0_row4\" class=\"row_heading level0 row4\" >randomForest</th>\n",
       "      <td id=\"T_3ab35_row4_col0\" class=\"data row4 col0\" >12.992407</td>\n",
       "      <td id=\"T_3ab35_row4_col1\" class=\"data row4 col1\" >0.106603</td>\n",
       "      <td id=\"T_3ab35_row4_col2\" class=\"data row4 col2\" >0.576981</td>\n",
       "      <td id=\"T_3ab35_row4_col3\" class=\"data row4 col3\" >0.499353</td>\n",
       "      <td id=\"T_3ab35_row4_col4\" class=\"data row4 col4\" >0.576981</td>\n",
       "      <td id=\"T_3ab35_row4_col5\" class=\"data row4 col5\" >0.493587</td>\n",
       "      <td id=\"T_3ab35_row4_col6\" class=\"data row4 col6\" >0.335510</td>\n",
       "      <td id=\"T_3ab35_row4_col7\" class=\"data row4 col7\" >0.576981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2e5886bcd30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        scaled_feat_matrix_lemma_2, # feature matrix\n",
    "        y_stars, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, accuracy score stayed roughly the same across all classifiers. Limiting to lemmas in 50% of documents did not help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Score Section\n",
    "\n",
    "Next, we used sentiment scoring as another method to try improving our classification. While sentiment scoring was something we learned early in the course and were hesitant to use on the final project, we decided to use it because it related so closely to the topic of reviews and associated ratings, which are at their most basic level an expression of feelings. The following few cells build sentiment columns into the existing review dataframe, and calculate average review sentiment using the emolex file we became familiar with during the semester. We take average sentence sentiment, and then average that to get review sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding sentiment score columns\n",
    "size = len(reviews)\n",
    "\n",
    "reviews['anger'] = np.zeros(size)\n",
    "reviews['anticipation'] = np.zeros(size)\n",
    "reviews['disgust'] = np.zeros(size)\n",
    "reviews['fear'] = np.zeros(size)\n",
    "reviews['joy'] = np.zeros(size)\n",
    "reviews['negative'] = np.zeros(size)\n",
    "reviews['positive'] = np.zeros(size)\n",
    "reviews['sadness'] = np.zeros(size)\n",
    "reviews['surprise'] = np.zeros(size)\n",
    "reviews['trust'] = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making stopwords list\n",
    "stoplist = stopwords.words('english')\n",
    "for el in [i for i in string.punctuation]:\n",
    "    stoplist.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_emolex function from INFO 3350 problem set code\n",
    "emolex_file = os.path.join('emolex.txt')\n",
    "\n",
    "def read_emolex(filepath=None):\n",
    "    '''\n",
    "    Takes a file path to the emolex lexicon file.\n",
    "    Returns a dictionary of emolex sentiment values.\n",
    "    '''\n",
    "    if filepath==None: # Try to find the emolex file\n",
    "        filepath = os.path.join('emolex.txt')\n",
    "        if os.path.isfile(filepath):\n",
    "            pass\n",
    "        elif os.path.isfile('emolex.txt'):\n",
    "            filepath = 'emolex.txt'\n",
    "        else:\n",
    "            raise FileNotFoundError('No EmoLex file found')\n",
    "    emolex = defaultdict(dict) # Like Counter(), defaultdict eases dictionary creation\n",
    "    with open(filepath, 'r') as f:\n",
    "    # emolex file format is: word emotion value\n",
    "        for line in f:\n",
    "            word, emotion, value = line.strip().split()\n",
    "            emolex[word][emotion] = int(value)\n",
    "    return emolex\n",
    "\n",
    "# Get EmoLex data. Make sure you set the right file path above.\n",
    "emolex = read_emolex(emolex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_text from INFO 3350 problem set code\n",
    "def tokenize_text(text, stops=[]):\n",
    "    sentences = []\n",
    "    for sent in sent_tokenize(text.lower()):\n",
    "        sentences.append([word for word in word_tokenize(sent) if word not in stops])\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "# sentence_sentiment_score from INFO 3350 problem set code\n",
    "def sentence_sentiment_score(toks, lexicon = emolex):\n",
    "    total = 0\n",
    "    emo_dict = defaultdict(lambda: 0)\n",
    "    \n",
    "    emotions = ['anger', 'anticipation','disgust','fear','joy','negative','positive','sadness','surprise', 'trust']\n",
    "    \n",
    "    \n",
    "    for word in toks:\n",
    "            total += 1\n",
    "            for emotion in emotions:\n",
    "                try:\n",
    "                    emo_dict[emotion] += lexicon[word][emotion]\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        if total > 0:\n",
    "            emo_dict[emotion] /= total\n",
    "        \n",
    "    return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_sentiment_df_update(sentence_dicts, df, index):\n",
    "    \n",
    "    reviewdict = dict({'anger': 0 , 'anticipation': 0,'disgust': 0,'fear': 0,'joy': 0,'negative': 0,'positive': 0,'sadness': 0,'surprise': 0, 'trust': 0})\n",
    "    \n",
    "    for sentence_dict in sentence_dicts:\n",
    "        for emotion in sentence_dict:\n",
    "            reviewdict[emotion] += sentence_dict[emotion]\n",
    "    \n",
    "    for emotion in reviewdict.keys():\n",
    "        reviewdict[emotion] /= len(sentence_dicts)\n",
    "        df.at[index, emotion] = reviewdict[emotion]\n",
    "    \n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for index, reviewtext in enumerate(reviews['text']):\n",
    "    sentence_dicts = []\n",
    "    for sentence in tokenize_text(reviewtext, stops=stoplist):\n",
    "        sentence_dicts.append(sentence_sentiment_score(sentence))\n",
    "    book_sentiment_df_update(sentence_dicts, reviews, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## data frame with sentiment scores added\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sent = reviews.groupby(['stars']).mean()\\\n",
    "[['anger','anticipation','disgust','fear','joy','negative','positive','sadness','surprise', 'trust']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Emotion scores of each star rating\")\n",
    "print(\"Column by Column Coloring: Green Indicates it is the highest value in that column\")\n",
    "grouped_sent.style.background_gradient(cmap='RdYlGn', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colorful graph above is helpful in understanding how well mean sentiment scores align with star ratings. We were pleasantly surprised by this graph.\n",
    "\n",
    "This graph is meant to be read column by column. The highest values in each column are colored green, and the lowest colored red.\n",
    "\n",
    "Looking down the columns for each sentiment, we see just what we would expect:\n",
    "- The \"bad\" emotions (anger, disgust, fear, negative, sadness) are on average highest in 1 star ratings and lowest in 5 star ratings. Not only this, but there is a perfect gradient of decreasing average score for these sentiments as you look from 1 star to 5 star ratings. \n",
    "- Similarly, for the \"good\" sentiments (joy, positive, trust), we see the opposite. 5 star ratings have highest average scores, and 1 star ratings have lowest average scores, with perfect gradients.\n",
    "\n",
    "This graph indicates to us that the sentiment analysis we did worked well on aggregate, and that on average, negative emotions are most associated with 1 star review, and positiove emotions are most associated with 5-star reviews. This gave us hope that our classifiers would do quite well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reviews[['anger','anticipation','disgust','fear','joy','negative','positive','sadness','surprise', 'trust']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(max_iter = 200),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers: \n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        train_df, # feature matrix\n",
    "        y_stars, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and f1 scores were worse across the board relative to when we used the same classifiers with a tfidf lemma matrix.\n",
    "This method resulted in just a 20% lift above baseline accuracy for the best performing algorithm, the Logit classifier. We moved on to looking at a relaxed scoring scheme and confusion matrix for more insight into why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg= LogisticRegression(max_iter=200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, y_stars, test_size=0.33, random_state=42)\n",
    "LogReg.fit(X_train, y_train)\n",
    "preds = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_within1 = 0\n",
    "for x,y in zip(preds, y_test):\n",
    "    if(abs(x-y) <= 1): count_within1 +=1\n",
    "\n",
    "print('Predictions that were correct or 1 star off: ', count_within1, '/', total, 'or ', round((count_within1/total) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1-star off scoring method improved accuracy score by a lot again, but it is still 15% lower than it was with the tfidf lemma feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, preds, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Classification Success')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_3cls = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in y_test]\n",
    "preds_3cls  = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in preds]\n",
    "print(\"Accuracy According to Relaxed Scoring Scheme: \", sum(np.array([1 if x==y else 0 for x,y in zip(y_test_3cls, preds_3cls)])) / total)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_3cls, preds_3cls, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Classification Success According to Relaxed Scoring Scheme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, because we had a well-aligned average sentiment score by star-rating chart, we thought using average review sentiment score would result in more successful classification. However, the above scores revealed that did not turn out to be the case. The two confusion matrices above, using two different scoring schemes, begin to show us why sentiment score did not perform well.\n",
    "\n",
    "The main conclusion here is that an overwhelming majority of reviews were being classified as 5 star, a few as 1 star, and none/almost none as 2, 3, or 4 stars. \n",
    "\n",
    "We believe the main reason 5 star reviews were so overrepresented in the predictions is because the 5 star reviews are over represented in the original dataset; almost half of the 15k reviews (7k) were 5-star.\n",
    "\n",
    "That being said, the same was true in the tfidf lemma feature matrix which performed much better, so we knew there must be another reason.\n",
    "\n",
    "After some thought, we realized that a lack of sentiment in many reviews could have resulted in a non-informative feature matrix, which made the algorithms so suscpetible to the bias in the initial set of reviews. While avergae sentiment across 1-5 star reviews was informative, individual reviews may not have had much sentiment. If there are only a couple of emotions scored per review, the classifier will not have enough information to properly asses each review. The averages may have clouded this aspect of the data, and the averages could have been skewed by some very aggressively positive or negative reviews at either end of the spectrum.\n",
    "\n",
    "Below, we look at the negativity and positive scores of the most negative and most positive reviews, and select the text from one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['negative'].nlargest(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['positive'].nlargest(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[6346].text, reviews.iloc[146].positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest average positivity score was around 0.15 for 5-star reviews, and the highest average negativity score was around 0.08 for 1-star reviews. The positivity and negativity scores above confirm our suspicion that some very positive and negative reviews may have skewing the avergaes, which gave us hope for good classification performance. The example text and positivity score shows how this could happen; short reviews and sentences with a high concentration of positive words gives very high average positivity.\n",
    "\n",
    "Below, we look at some more informative statistics on the distribution of sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart above shows that sentiment scores across all reviews are dominated by scores of zero in many cases, and in other cases have slightly fewer zeros but tiny standard deviations. The dominance of completely uninformative zeros in the dataset, paired with very small variation in scores that are nonzero makes us think that these characteristics made the feature matrix poor, resulting in low accuracy scores across all classifiers.\n",
    "\n",
    "Below, I implement word embeddings, which are sort of a more complex version of sentiment analysis. They turn each word into a 300 component long vector, and then average the words in each review to get the mean review for the vector. I am hoping that the larger number of compoenents in embeddings relative to the above sentiment analysis (300 vs 10) will help accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embedding attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Helper functions from p_08 answer key\n",
    "\n",
    "# Function(s) to calculate embeddings from text\n",
    "def remove_noninformative_tokens(doc):\n",
    "    '''\n",
    "    Takes a spacy-processed document.\n",
    "    Returns a list of spacy token objects without stopwords, punctuation, or embedding-less tokens.\n",
    "    '''\n",
    "    culled = [token for token in doc if not (token.is_stop or token.is_punct or token.is_space) and token.has_vector]\n",
    "    return(culled)\n",
    "\n",
    "def get_doc_embedding(text, nlp):\n",
    "    '''\n",
    "    Takes a document as a text string and a loaded spaCy nlp object.\n",
    "    Returns a vector representation of the document.\n",
    "    '''\n",
    "    doc = nlp(text)\n",
    "    culled = remove_noninformative_tokens(doc)\n",
    "    embedding = np.mean([token.vector for token in culled], axis=0)\n",
    "    if np.isnan(embedding).any():\n",
    "        embedding = np.zeros([1,nlp.vocab.vectors_length])\n",
    "        print(f\"There was a problem with document {i}\\nText: {text}\\n\")\n",
    "    return(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This was run once and then commented out because after creating the embeddings, we saved the file to avoid running this cell again,\n",
    "## because it takes a while to run.\n",
    "\n",
    "\n",
    "### %%time\n",
    "### # Vectorize embeddings\n",
    "### import spacy\n",
    "### import datetime\n",
    "### nlp = spacy.load(\"en_core_web_lg\")\n",
    "### \n",
    "### X_embed = np.zeros([len(reviews), nlp.vocab.vectors_length])\n",
    "### for i, text in enumerate(reviews.text):\n",
    "###     if i%1000 == 0:\n",
    "###         print(f'{i:<5} documents processed @ {datetime.datetime.now()}')\n",
    "###     X_embed[i] = get_doc_embedding(text, nlp)\n",
    "### print(X_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##with open('X_embed.pickle', 'wb') as f:\n",
    "##    pickle.dump(X_embed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed = pd.read_pickle(r'X_embed.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(max_iter = 500),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "scores = {} # Store cross-validation results in a dictionary\n",
    "for classifier in classifiers:\n",
    "    print(f'{classifier} starting @ {datetime.datetime.now()}')\n",
    "    scores[classifier] = cross_validate( # perform cross-validation\n",
    "        classifiers[classifier], # classifier object\n",
    "        X_embed, # feature matrix\n",
    "        y_stars, # gold labels\n",
    "        cv=10, #number of folds\n",
    "        scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro'] # scoring methods\n",
    "    )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we see that word embeddings resuted in improved accuracy and f1 across the board. Logit still scored the best, with an accuracy of 63.9% the best accuracy we have seen thus far!\n",
    "\n",
    "Though it is only a small lift over the tfidf lemma matrix, it is a large increase relative to averaged sentence sentiment. Below, please see the relaxed scoring methods we have used for other feature matrices again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split of the full feature matrix\n",
    "LogReg= LogisticRegression(max_iter = 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embed, y_stars, test_size=0.33, random_state=42)\n",
    "LogReg.fit(X_train, y_train)\n",
    "preds = LogReg.predict(X_test)\n",
    "print('Correct Predictions: ', accuracy_score(y_test, preds), '= 64.2%')\n",
    "\n",
    "count_within1 = 0\n",
    "for x,y in zip(preds, y_test):\n",
    "    if(abs(x-y) <= 1): count_within1 +=1\n",
    "    \n",
    "total = len(preds)\n",
    "\n",
    "print('Predictions that were correct or 1 star off: ', count_within1, '/', total, 'or ', round((count_within1/total) * 100, 2), '%')\n",
    "\n",
    "y_test_3cls = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in y_test]\n",
    "preds_3cls  = ['Bad' if x in [1,2] else ('Okay' if x == 3 else 'Good') for x in preds]\n",
    "print(\"Accuracy According to Relaxed 3-class Scoring Scheme: \", round(sum(np.array([1 if x==y else 0 for x,y in zip(y_test_3cls, preds_3cls)])) / total, 4)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, preds, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Review Classification Success')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test_3cls, preds_3cls, normalize = 'true', cmap = 'RdYlGn')\n",
    "plt.title('Confusion Matrix Displaying Classification Success According to Relaxed Scoring Scheme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across the board, we see very similar patterns to what we saw with the tfidf lemma matrix, with slightly elevated accuracy. Some interesting things to note:\n",
    "\n",
    "- Though embeddings had higher overall accuracy, more 2-star ratings were confused with 1-star ratings (0.38 v 0.34), and more 4-star ratings were confused with 5-star ratings(0.57 v 0.5), than with tfidf lemma matrix. \n",
    "- Emeddings did slightly worse overall with 2, 3, and 4 star ratings than the tfidf lemma matrix (0.18, 0.26, 0.32 v 0.22, 0.26, 0.35).\n",
    "- Embeddings more than made up for this by more accuractely classifying 1 and 5 star ratings better than tfidf lemma (0.82 v 0.75 and 0.87 v 0.84) resulting in higher overall accuracy, because there are so many 5 star ratings in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Business type topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop(['useful','cool','date','funny','latitude','longitude','stars_y','is_open','hours'], axis=1)\n",
    "#combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cat = []\n",
    "\n",
    "for category in combined['categories']:\n",
    "    cat = category.split(',')[0]\n",
    "    main_cat.append(cat)\n",
    "    \n",
    "combined['category'] = main_cat\n",
    "#combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy, fraction of businesses that are restaurants\n",
    "\n",
    "baseline = len(combined[combined['category'].str.contains('Restaurants')]) / len(combined)\n",
    "print('Baseline accuracy for restaurants in the data:', baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary list -- yes or no restaurant\n",
    "countrest = []\n",
    "\n",
    "for category in combined['category']:\n",
    "    if category == 'Restaurants':\n",
    "        countrest.append(1)\n",
    "    else:\n",
    "        countrest.append(0)\n",
    "\n",
    "# add binary restaurant column\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    combined['restaurant'] = countrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_w = CountVectorizer( \n",
    "    input = 'content',\n",
    "    encoding = 'utf-8',\n",
    "    strip_accents = 'unicode',\n",
    "    stop_words= stoplist, \n",
    "    lowercase = True,\n",
    "    min_df = 0.01, \n",
    "    max_df = 0.5 \n",
    ")\n",
    "\n",
    "X_w = vectorizer_w.fit_transform(combined['text'])\n",
    "print(\"Feature matrix shape, all reviews:\", X_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_w = LatentDirichletAllocation(\n",
    "    n_components=50, \n",
    "    n_jobs=-1,     \n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "lda_w.fit(X_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc topic matrix\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    doc_topic_matrix_w = lda_w.transform(X_w)\n",
    "print(\"All reviews doc-topic matrix shape:\", doc_topic_matrix_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From lecture 20-21\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words, hide_stops=False):\n",
    "    if hide_stops:\n",
    "        from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Topic {topic_idx: >2}: \"\n",
    "        top_words_idx = topic.argsort()\n",
    "        if not hide_stops:\n",
    "            top_words = [feature_names[i]\n",
    "                         for i in top_words_idx[:-n_top_words - 1:-1]]\n",
    "        else:\n",
    "            top_words = []\n",
    "            i = 1\n",
    "            while len(top_words) < n_top_words:\n",
    "                if feature_names[top_words_idx[-i]] not in ENGLISH_STOP_WORDS:\n",
    "                    top_words.append(feature_names[top_words_idx[-i]])\n",
    "                i += 1\n",
    "        message += \" \".join(top_words)    \n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50 topics from the entire dataset \\n')\n",
    "print_top_words(lda_w, vectorizer_w.get_feature_names_out(), n_top_words=10, hide_stops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot -- lecture 20-21\n",
    "# Adapted from Seaborn docs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sns.set_context('talk')\n",
    "corr = np.corrcoef(doc_topic_matrix_w.T)\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(20, 230, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask, \n",
    "    cmap=cmap, \n",
    "    center=0,\n",
    "    square=True, \n",
    "    linewidths=.5, \n",
    "    cbar_kws={\"shrink\": .5}\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The heat map above shows the correlation between each topic in the topic matrix. The fact that we used 50 topics in the model makes the graph a bit difficult to read, but there are a few \"hot spots\" of blue and red that indicate interesting correlations between two topics.\n",
    "\n",
    "#### Positive correlations\n",
    "- 32 and 43\n",
    "- 33 and 43\n",
    "- 4 and 31\n",
    "\n",
    "--- \n",
    "\n",
    "Topic  4: sandwich burger good fries like burgers really would one got\n",
    "\n",
    "Topic 31: cheese sauce steak mac bbq meat ribs onions dry sauces\n",
    "\n",
    "***Both of these topics involve meat and make us think of classic \"American\" food.***\n",
    "\n",
    "---\n",
    "\n",
    "Topic 32: service customer phone call called would time work delivery arrived\n",
    "\n",
    "Topic 43: would us told company said day called card back credit\n",
    "\n",
    "***These topics hint at calling and customer service.***\n",
    "\n",
    "---\n",
    "\n",
    "Topic 33: car back would review get reviews since another still\n",
    "\n",
    "Topic 43: would us told company said day called card back credit\n",
    "\n",
    "***These topics are somewhat of a mystery but also hint at customer service.***\n",
    "\n",
    "---\n",
    "\n",
    "#### Negative correlations \n",
    "- 17 and 48\n",
    "- 17 and 41\n",
    "- 17 and 42\n",
    "\n",
    "***Topic 17 had the most strong negative correlations based on the graph (most dark red squares in the 17 column)***\n",
    "\n",
    "---\n",
    "\n",
    "Topic 17: great good food service drinks bar atmosphere place friendly go\n",
    "\n",
    "Topic 41: said asked back like get rude time manager could one\n",
    "\n",
    "***These are opposite experiences of good vs bad customer service.***\n",
    "\n",
    "---\n",
    "\n",
    "Topic 17: great good food service drinks bar atmosphere place friendly go\n",
    "\n",
    "Topic 42: help time like care thank store questions made helped \n",
    "\n",
    "***When reading these, they both signal good experiences for customers, so this is an unexpected negative correlation. However, Topic 17 has a specific place associated with it (drinks, bar, etc.), so that may be where the negative correlation stems from.***\n",
    "\n",
    "--- \n",
    "\n",
    "Topic 17: great good food service drinks bar atmosphere place friendly go\n",
    "\n",
    "Topic 48: would could told even one thought experience make get give\n",
    "\n",
    "***The jumble of words from 48 may signify that incoherence skews the topics and therefore these are different for an inexplicable reason by humans.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we scale the topic matrix so that it can be passed into multiple classifiers to find the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make topic matrix\n",
    "X_w_topics = StandardScaler().fit_transform(doc_topic_matrix_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'kNN': KNeighborsClassifier(),\n",
    "    'Logit':LogisticRegression(),\n",
    "    'decisionTree': DecisionTreeClassifier(),\n",
    "    'randomForest':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores = {} \n",
    "    for classifier in classifiers: \n",
    "        scores[classifier] = cross_validate(\n",
    "            classifiers[classifier], \n",
    "            X_w_topics,\n",
    "            countrest, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "        )\n",
    "    \n",
    "compare_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the topic modeling, we can see that classifying whether a business is a restaurant or not based on the topic matrix performs relatively well, and definitely better than the baseline. The chart shows us that our highest performing classifier, Logistic Regression, has F1 = 0.75 and accuracy = 0.82.\n",
    "\n",
    "This realtively good performance makes sense because many of the topics (printed above) have specific food related words in the reviews that make it more apparent that it is a restaurant. It seems reasonable that the performance is not higher, though, because some of the topics contain generally applicable words such as \"good\", \"service\", \"like\", \"bad\", \"love\", and \"wait\", to name a few. These words skew the relevance of topics to be applicable to all businesses, making it more difficult to differentiate between a restaurant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we try to improve classification by changing the number of topics. We hypothesized that adding more topics would improve the classification because the topic model would would become more specific and possibly provide more restaurant-specific topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_w_100 = LatentDirichletAllocation(\n",
    "    n_components=100, \n",
    "    n_jobs=-1,     \n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "lda_w_100.fit(X_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc topic matrix\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    doc_topic_matrix_100 = lda_w_100.transform(X_w)\n",
    "print(\"Doc-topic matrix of whole dataset shape:\", doc_topic_matrix_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w_100 = StandardScaler().fit_transform(doc_topic_matrix_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores2 = {} # Store cross-validation results in a dictionary\n",
    "    for classifier in classifiers: \n",
    "        scores2[classifier] = cross_validate(\n",
    "            classifiers[classifier], \n",
    "            X_w_100, \n",
    "            countrest, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "        )\n",
    "    \n",
    "compare_scores(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding more topics basically did not change any of the classification outputs. We also tried with 10 and 500 topics (not shown), and there was still no change. This was unexpected because we thought more topics would provide more restaurant-specific information. These results probably reflect the number of reviews that are general (\"good\", \"service\", \"bad\", etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From here, we were curious about the topic model for only restaurants. Would the topcis be more restaurant specific?\n",
    "\n",
    "We decided to narrow down the dataset to just restaurants and then classify into different types of restaurants with a topic model of the new restaurant dataset. We hypothesized that topics of the reviews of only restaurants would include cuisine-specific words. Based on the prevalence of these topics in different reviews, the classifier would perform well for deciding if a review was for a certain type of restaurant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df = pd.DataFrame(combined[combined['category'].str.contains('Restaurants')])\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to get an idea of the categories we'll make\n",
    "restaurant_df['categories'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The list above shows the top \"sub-categories\" amongst the restaurant reviews. We will use this to inform our top five cuisine types that we will perform classification on using topic modeling of the restaurant dataset. \n",
    "\n",
    "#### Based on the list, our multiclass classification gold labels will be Mexican (1), Pizza (2), Chinese (3), Italian (4), American (5, combining New and Traditional), and other (6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column with cuisine\n",
    "cuisine = []\n",
    "\n",
    "for category in restaurant_df['categories']:\n",
    "    cat = category.split(',')\n",
    "    if (len(cat) > 1):\n",
    "        cat = category.split(',')[1]\n",
    "        cat = cat[1:]\n",
    "        cuisine.append(cat)\n",
    "    else:\n",
    "        cuisine.append('N/A')\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    restaurant_df['cuisine'] = cuisine\n",
    "\n",
    "#restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add numbers associated with each cuisine to dataframe\n",
    "y_cuisine = []\n",
    "\n",
    "for cuisine in restaurant_df['cuisine']:\n",
    "    if cuisine == 'Mexican':\n",
    "        y_cuisine.append(1)\n",
    "    elif cuisine == 'Pizza':\n",
    "        y_cuisine.append(2)\n",
    "    elif cuisine == 'Chinese':\n",
    "        y_cuisine.append(3)\n",
    "    elif cuisine == 'Italian':\n",
    "        y_cuisine.append(4)\n",
    "    elif cuisine == 'American (New)' or cuisine == 'American (Traditional)':\n",
    "        y_cuisine.append(5)\n",
    "    else:\n",
    "        y_cuisine.append(6)\n",
    "        \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    restaurant_df['y_cuisine'] = y_cuisine\n",
    "    \n",
    "#restaurant_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_r = CountVectorizer( \n",
    "    input = 'content',\n",
    "    encoding = 'utf-8',\n",
    "    strip_accents = 'unicode',\n",
    "    stop_words= stoplist, \n",
    "    lowercase = True,\n",
    "    min_df = 0.01, \n",
    "    max_df = 0.5 \n",
    ")\n",
    "\n",
    "X_r = vectorizer_r.fit_transform(restaurant_df['text'])\n",
    "print(\"Feature matrix shape, restaurant reviews:\", X_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_r = LatentDirichletAllocation(\n",
    "    n_components=50, \n",
    "    n_jobs=-1,     \n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "lda_r.fit(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc topic matrix\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    doc_topic_matrix = lda_r.transform(X_r)\n",
    "print(\"Restaurant reviews doc-topic matrix shape:\", doc_topic_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('50 topics from the entire dataset \\n')\n",
    "print_top_words(lda_r, vectorizer_r.get_feature_names_out(), n_top_words=10, hide_stops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores3 = {}\n",
    "    for classifier in classifiers: \n",
    "        scores3[classifier] = cross_validate(\n",
    "            classifiers[classifier],\n",
    "            X_topics, \n",
    "            y_cuisine,\n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "        )\n",
    "        \n",
    "compare_scores(scores3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It makes sense that this subset performed worse than the \"restaurant vs other\" classifier because adding more categories makes prediction more difficult. Additionally, given what we know about the general topics of many reviews and even the overlap of different food-specific words (e.g., \"sauce\" could apply to Pizza and Mexican), it is actually surprising that the classifier did so well.\n",
    "\n",
    "#### The chart above shows the classification performance for four different classifiers compared to the baseline multiclass classification. Since Random Forest performed the best, we will change some parameters to try and improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to improve the random forest\n",
    "RFfeatures = {\n",
    "    'feature_None':RandomForestClassifier(max_features=None),\n",
    "    'feature_50':RandomForestClassifier(max_features=50),\n",
    "    'feature_10':RandomForestClassifier(max_features=10),\n",
    "    'feature_5':RandomForestClassifier(max_features=10),\n",
    "    'feature_2':RandomForestClassifier(max_features=2)\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    RFscores = {} \n",
    "    for classifier in RFfeatures:\n",
    "        RFscores[classifier] = cross_validate( \n",
    "            RFfeatures[classifier], \n",
    "            X_topics, \n",
    "            y_cuisine, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "        )\n",
    "\n",
    "compare_scores(RFscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we see that the Random Forest Classifier with 5 max features, meaning the classifier can only try up to five features per node (i.e., the number of options to consider for classification).\n",
    "\n",
    "#### From a baseline F1 of 0.51 to our best F1 of 0.60, a 0.10 increase is not bad! Additionally, the accuracy increased by almost 0.20.\n",
    "\n",
    "#### Our final test is to see how classifiers perform on a binary ***within*** the restaurant subset. Can we determine if a restaurant is Mexican or not based on topic modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make binary columnn for Mexican gold labels\n",
    "y_mex = []\n",
    "\n",
    "for cuisine in restaurant_df['cuisine']:\n",
    "    if cuisine == 'Mexican':\n",
    "        y_mex.append(1)\n",
    "    else:\n",
    "        y_mex.append(0)\n",
    "        \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    restaurant_df['mexican'] = y_mex\n",
    "    \n",
    "#restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores4 = {}\n",
    "    for classifier in classifiers: \n",
    "        scores4[classifier] = cross_validate(\n",
    "            classifiers[classifier],\n",
    "            X_topics, \n",
    "            y_mex,\n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "        )\n",
    "        \n",
    "compare_scores(scores4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying cuisines as a binary performs very well! \n",
    "\n",
    "This makes sense because in the document topic matrix for only restaurants, the weight that cuisine-specific topics have (Topic 29: taco good prices bit really large got order restaurant big) makes the cuisine-specific reviews stand out to the classifier. While it is gratifying to have a classifier perform so well, we recognize that this is not the most challenging task and does not provide much new insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results Summary\n",
    "\n",
    "In terms of our first two questions regarding what algorithms and feature matrices were most effective for using review text to predict star ratings, we found that Logistic Regression was the most effective algorithm across all feature matrices, with Random Forest in second. Decision Tree and K Nearest Neighbors were both further behind. Additionally we found that a tfidf lemma feature matrix resulted in much better accuracy than an average review sentiment feature matrix. As discussed above, many reviews lacked enough sentiment across each emotion to inform the classifiers enough, resulting in a strong bias towards 5-star reviews, the most common review in the dataset. Finally, we tried to fix that issue by using word embeddings. This resulted in the highest accuracy yet, around 64%, or a 34% lift over baseline accuracy. This was because the word embeddings included a lot of sensitivity and information per word, making up for the shortcomings of the more simple sentiment analysis.\n",
    "\n",
    "For algorithms and topic modeling, we found that Logistic Regression was the most effective for predicting whether a review was for a restaurant or not when applied to the entire dataset. When moving into the restaurant subset of the data, we found that the Random Forest algorithm with max_features = 5 performed the best for our multiclass question of cuisine prediction (Mexican, Pizza, Chinese, Italian, American, Other). Finally, we explored the performance of a binary cuisine question within the restaurant subset (Mexican vs Other) based on topic modeling and found this to be overall the most successful, which makes sense because cuisine-specific words would improve the classification for one specific type of cuisine (as opposed to choosing one of six, as with the multiclass question)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Topic Model Final Improvement: Restaurant vs Not Restaurant review in entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers1 = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'Logit':LogisticRegression()\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores11 = {} \n",
    "    for classifier in classifiers1: \n",
    "        scores11[classifier] = cross_validate(\n",
    "            classifiers1[classifier], \n",
    "            X_w_topics,\n",
    "            countrest, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "        )\n",
    "    \n",
    "compare_scores(scores11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Topic Model Final Improvement: Multiclass cuisine in restaurant subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers2 = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'randomForest': RandomForestClassifier(max_features=5)\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores12 = {} \n",
    "    for classifier in classifiers2: \n",
    "        scores12[classifier] = cross_validate(\n",
    "            classifiers2[classifier], \n",
    "            X_topics,\n",
    "            y_cuisine, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "        )\n",
    "    \n",
    "compare_scores(scores12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Model Final Improvement: Binary cuisine (Mexican vs Not) in restaurant subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifers to test\n",
    "classifiers3 = {\n",
    "    'Baseline': DummyClassifier(strategy = 'stratified'),\n",
    "    'randomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    scores13 = {} \n",
    "    for classifier in classifiers3: \n",
    "        scores13[classifier] = cross_validate(\n",
    "            classifiers3[classifier], \n",
    "            X_topics,\n",
    "            y_mex, \n",
    "            cv=10, \n",
    "            scoring=['accuracy','precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "        )\n",
    "    \n",
    "compare_scores(scores13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Discussion & Conclusion\n",
    "\n",
    "In conclusion, both tfidf lemma and sentiment scored feature matrices resulted in varying lift above baseline accuracy. Sentiment scoring however was not particularly effective, and was limited by a lack of some emotions detected in many reviews. Perhaps a more finely tuned approach such as word embeddings would better capture the meaning and emotion of each sentence, and result in higher accuracy; the limitation to ten emotions could be part of the reason why sentiment scoring was not working well. We overcame this limitation by using word embeddings, to achieve our highest ever accuracy. That being said, word embeddings are not without limitations. They average the whole sentence, which may dampen or overrepresent some strong emotions in the dataset. Using features that include more information on the actual range of scores along each reviews 300 component averaged vector. This could improve accuracy. Another general limitation had to do with the dataset itself. There were many more 5-star reviews than any other type of review, which may have biased the dataset. While balancing classes might have reduced bias, it might have also reduced accuracy scores; in some ways the bias of the dataset was useful for the classifiers, because it reflected a real tendency in the data that then became built into the classifiers.\n",
    "\n",
    "Topic modeling was a successful way to classify different aspects of the dataset, including whether or not a review was for a restaurant, what type of cuisine a restaurant was, and if a restaurant was Mexican or not. Using topic modeling made sense because we hypothesized that the topics would reveal specific information about these various questions based on the specific words in each topic.\n",
    "\n",
    "There were some limitations with the topic modeling because of the setup of the original data. The original \"categories\" column was an English list (not a list type) that separated each category of the business with a comma. Additionally, the list for each business was not in any priority otder, so, for example, some businesses had \"Restaurants\" listed first, while other had it listed third or fourth. Retrieving this information required some string maneuvering which led us to the decision that we would only deal with the first and second listed categories of each review. This means we probably lost some reviews that could have been counted as restaurants and then further within the cuisines we chose to analyze. Another limitation was the repetition of words that could have been lemmatized. We also could have updated our list of stopwords specifically for the restaurant reviews to get more targeted and meaningful results, because we saw the repetition of many general words such as \"like\", \"good\", \"bad\", etc.\n",
    "\n",
    "Overall, this was a fun exploration of Yelp reviews. This project was enjoyable because we had the freedom to apply what we learned on longer novels and literature to shorter, modern text. This project showed us how useful the tools from this class can be for current data sources, as well as historical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
